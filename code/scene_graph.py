import json
import os
import torch
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor
from PIL import Image

# ================= è·¯å¾„é…ç½®åŒºåŸŸ =================

# 1. æ¨¡å‹æœ¬åœ°è·¯å¾„ (ä¿æŒä¸å˜)
MODEL_PATH = "/storage/nvme/Qwen3-VL-4B-Instruct"

# 2. æ•°æ®é›†æ ¹ç›®å½• (ä¿æŒä¸å˜)
DATASET_ROOT = "/storage/nvme/Customized_LLM/my_dataset"

# 3. å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
IMAGE_DIR = os.path.join(DATASET_ROOT, "images")

# 4. è¾“å…¥çš„å…ƒæ•°æ®æ–‡ä»¶
INPUT_JSON_FILE = os.path.join(DATASET_ROOT, "caption.json") 

# 5. è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„
OUTPUT_FILE = os.path.join(DATASET_ROOT, "scene_graph.json")

# ================= æ ¸å¿ƒé€»è¾‘ =================

def load_model():
    """
    åŠ è½½ Qwen3-VL æ¨¡å‹
    ä¿®å¤ç‚¹: ä½¿ç”¨ Qwen2VLForConditionalGeneration è€Œé AutoModelForCausalLM
    """
    print(f"æ­£åœ¨ä»æœ¬åœ°åŠ è½½ Qwen3 æ¨¡å‹: {MODEL_PATH} ...")
    
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹è·¯å¾„ {MODEL_PATH}")

    model = Qwen3VLForConditionalGeneration.from_pretrained(
        MODEL_PATH,
        dtype=torch.bfloat16, 
        device_map="cuda:0",
    )


    # åŠ è½½å¤„ç†å™¨
    processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)
    return model, processor

def build_prompt_content(caption):
    """æ„å»º Prompt æ–‡æœ¬å†…å®¹"""
    system_text = f"""
Analyze the image with the caption: "{caption}".
    Extract structured information into a strictly valid JSON format.
    
    ### STRICT GUIDELINES:
    1. **Identity Retention**: 
       - If the caption contains "I", "me", or "my", the participant MUST be labeled as "User".
       - If the caption contains a name (e.g., "Tom", "Jack"), use the Name. Do NOT change "Jack" to "boy".
    2. **Format Consistency**:
       - "participants": A list of strings.
       - "relations": Include < "subject", "action", "object" >, all participant MUST appear in relations.
       - "atmosphere": ALWAYS a list of strings (e.g., ["sunny", "happy"]). Do not use a single string.
    3. **Entity Consistency**:
       - Use the exact terminology from the caption for objects if available (e.g., if caption says "canoe", do not output "boat").

    ### JSON SCHEMA:
    {{
        "event_summary": "Short phrase summarizing the event",
        "location": "Where is this happening? (Infer from image + caption)",
        "participants": ["List of main objects/people"],
        "relations": [
            {{"subject": "Entity A", "action": "interaction verb", "object": "Entity B"}}
        ],
        "atmosphere": ["vibe1", "vibe2", "vibe3"]
    }}
    
    Output ONLY the raw JSON string.
    """
    return system_text.strip()

def parse_model_output(output_text):
    """æ¸…æ´—æ¨¡å‹è¾“å‡º"""
    clean_text = output_text.replace("```json", "").replace("```", "").strip()
    try:
        return json.loads(clean_text)
    except json.JSONDecodeError:
        try:
            start = clean_text.find('{')
            end = clean_text.rfind('}') + 1
            if start != -1 and end != -1:
                return json.loads(clean_text[start:end])
        except:
            pass
        # ä»…æ‰“å°å‰50å­—ç¬¦é˜²æ­¢åˆ·å±
        print(f"Warning: JSON decode failed. Raw: {clean_text[:50]}...")
        return {"raw_text_fallback": clean_text, "error": "JSON_DECODE_ERROR"}

def clean_scene_graph(struct_data):
    """
    æ¸…æ´—é€»è¾‘ï¼š
    1. å»é™¤é‡å¤çš„ participantsã€‚
    2. ç§»é™¤æœªåœ¨ relations ä¸­å‡ºç°çš„ participantsã€‚
    """
    # å¦‚æœè§£æå‡ºé”™æˆ–æ•°æ®ä¸ºç©ºï¼Œç›´æ¥è¿”å›
    if not struct_data or "error" in struct_data:
        return struct_data

    # è·å–åŸå§‹æ•°æ®
    raw_participants = struct_data.get("participants", [])
    relations = struct_data.get("relations", [])

    # 1. æ”¶é›†æ‰€æœ‰åœ¨ relations ä¸­â€œæ´»è·ƒâ€å‡ºç°çš„å®ä½“
    active_entities = set()
    for rel in relations:
        # æ”¶é›† subject
        if "subject" in rel and isinstance(rel["subject"], str):
            active_entities.add(rel["subject"])
        # æ”¶é›† object
        if "object" in rel and isinstance(rel["object"], str):
            active_entities.add(rel["object"])

    # 2. æ¸…æ´— participants
    # é€»è¾‘: å…ˆè½¬ set å»é‡ï¼Œå†éå†æ£€æŸ¥æ˜¯å¦åœ¨ active_entities ä¸­
    final_participants = []
    
    # ä½¿ç”¨ set å»é‡ raw_participants (é˜²æ­¢åˆ—è¡¨é‡Œæœ‰ ["Man", "Man"])
    unique_raw_participants = list(set(raw_participants))

    for p in unique_raw_participants:
        # åªæœ‰å½“ participant å­˜åœ¨äºå…³ç³»ç½‘ç»œä¸­æ—¶æ‰ä¿ç•™
        if p in active_entities:
            final_participants.append(p)
            
    # 3. è¦†ç›–åŸæ•°æ®
    struct_data["participants"] = final_participants
    
    return struct_data

def main():
    with open(INPUT_JSON_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"æ•°æ®æ¡æ•°: {len(data)}")
    print("ç¬¬ä¸€æ¡æ•°æ®æ ·ä¾‹:")
    print(json.dumps(data[0], ensure_ascii=False, indent=2))

    # 1. åˆå§‹åŒ–æ¨¡å‹
    try:
        model, processor = load_model()
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½ä¸¥é‡é”™è¯¯: {e}")
        print("è¯·ç¡®è®¤ transformers ç‰ˆæœ¬æ˜¯å¦æ›´æ–°: pip install --upgrade transformers")
        return

    # 2. æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(INPUT_JSON_FILE):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {INPUT_JSON_FILE}")
        return

    with open(INPUT_JSON_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    results = []
    print(f"ğŸš€ å¼€å§‹å¤„ç†ï¼Œå…± {len(data)} æ¡æ•°æ®...")

    MAX_RETRIES = 3

    # 3. éå†æ•°æ®
    for i, entry in enumerate(data):
        # å…¼å®¹ä¸åŒçš„é”®å
        image_filename = entry.get('image_file') or entry.get('file_name')
        caption = entry.get('caption', '')
        
        if not image_filename:
            continue

        image_path = os.path.join(IMAGE_DIR, image_filename)
        if not os.path.exists(image_path):
            print(f"è·³è¿‡: å›¾ç‰‡ä¸å­˜åœ¨ {image_path}")
            continue

        # æ„é€  Qwen3/Qwen2-VL æ ¼å¼æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image_path},
                    {"type": "text", "text": build_prompt_content(caption)},
                ],
            }
        ]

        # é¢„å¤„ç†
        inputs = processor.apply_chat_template(
            messages,
            tokenize=True,
            add_generation_prompt=True,
            return_dict=True,
            return_tensors="pt"
        )

        inputs = inputs.to(model.device)

        struct_data = {}
        
        for attempt in range(MAX_RETRIES):
            try:
                with torch.no_grad():
                    # å…³é”®ä¿®æ”¹: å¼€å¯ do_sample=Trueï¼Œè®©æ¯æ¬¡ç”Ÿæˆçš„ token æœ‰å¾®å°å˜åŒ–
                    # temperature å¯ä»¥éšé‡è¯•æ¬¡æ•°å¾®è°ƒï¼Œå¢åŠ å˜æ•°
                    current_temp = 0.6 + (attempt * 0.1) 
                    
                    generated_ids = model.generate(
                        **inputs, 
                        max_new_tokens=512,
                        do_sample=True,       # å¿…é¡»å¼€å¯ï¼Œå¦åˆ™æ¯æ¬¡é‡è¯•ç»“æœéƒ½ä¸€æ ·
                        temperature=current_temp, 
                        top_p=0.9
                    )

                generated_ids_trimmed = [
                    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
                ]
                
                output_text = processor.batch_decode(
                    generated_ids_trimmed, 
                    skip_special_tokens=True, 
                    clean_up_tokenization_spaces=False
                )[0]

                # å°è¯•è§£æ
                parsed_result = parse_model_output(output_text)

                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æ ‡è®° (åŸºäº parse_model_output çš„è¿”å›é€»è¾‘)
                if "error" in parsed_result and parsed_result["error"] == "JSON_DECODE_ERROR":
                    print(f"âš ï¸ [ç´¢å¼• {i}] ç¬¬ {attempt + 1} æ¬¡ç”Ÿæˆ JSON è§£æå¤±è´¥ï¼Œæ­£åœ¨é‡è¯•...")
                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ä¾ç„¶å¤±è´¥
                    if attempt == MAX_RETRIES - 1:
                        print(f"âŒ [ç´¢å¼• {i}] é‡è¯•è€—å°½ï¼Œä¿ç•™åŸå§‹é”™è¯¯æ–‡æœ¬ã€‚")
                        struct_data = parsed_result
                else:
                    # è§£ææˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    struct_data = clean_scene_graph(parsed_result)
                    # å¦‚æœæ˜¯é‡è¯•åæˆåŠŸçš„ï¼Œæ‰“å°ä¸€ä¸‹æç¤º
                    if attempt > 0:
                        print(f"âœ… [ç´¢å¼• {i}] åœ¨ç¬¬ {attempt + 1} æ¬¡å°è¯•åæˆåŠŸä¿®å¤ã€‚")
                    break
            
            except Exception as e:
                print(f"æ¨ç†è¿‡ç¨‹å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                if attempt == MAX_RETRIES - 1:
                    struct_data = {"error": str(e)}
        
        final_entry = {
            "original_data": entry,
            "scene_graph": struct_data
        }
        results.append(final_entry)
        
        if i % 10 == 0:
            print(f"è¿›åº¦: {i}/{len(data)} å·²å®Œæˆ")
            if i > 0:
                with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)

    # 4. æœ€ç»ˆä¿å­˜
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()